# Training configuration

# Training duration
epochs: 150
early_stopping_patience: 20

# Optimizer
optimizer:
  name: adamw
  lr: 0.0001
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-08

# Scheduler
scheduler:
  name: cosine
  warmup_epochs: 5
  min_lr: 1.0e-06
  step_size: 30
  gamma: 0.1

# Loss function
loss_type: combined
dice_weight: 0.5
ce_weight: 0.5

# Training settings
use_amp: true
gradient_clip_val: 1.0

# Checkpointing
save_every_n_epochs: 10
save_best: true
save_last: true

# Validation
val_every_n_epochs: 1

# Paths
checkpoint_dir: experiments/checkpoints
log_dir: logs
tensorboard_dir: experiments/runs

# Resume training
resume_from_checkpoint: null

# Random seed
seed: 42
deterministic: true